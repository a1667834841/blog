---
title: 2021-03-31_note
date: 2022-11-13 23:10:11
permalink: /pages/e4a5b9/
categories:
  - 每日随笔
  - 2021-03
tags:
  - 
---
**mood:** :smile:  																		**date: 2021-03-31**  
## 今日计划  
------
- [ ]  
## 明日计划  
------
- [ ]  
## 随写 
------

kafka 生产者 特性 

**分区策略**：

1.直接指明分区，

2.没有指定分区，但是传入key,可以根据key的hash值 与分区的数量求余，得到最后的分区值

3.两个都没有的情况下，采用轮询，第一次随机产生一个整数，与topic的分区数求余，然后下一次整数+1

**保证数据一致性**：发送者向topic发送消息，保证数据到达topic，可以采用三种方式 延迟依次递增

1. 直接发送topic ，不需要确认
2. 半数以上的分区完成同步，才发送ack
3. 全部同步完成，才发送ack



kafka 消费者特性

1. 消费方式

- pull 会根据消费者的能力来消费数据 可以设置 timeout 多长时间取一次
- push  以最快的速度消费消息 很容易造成服务器压力大，网络堵塞

offset的维护

1. Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中
2. 从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为_consumer_offsets。

springApplication 启动机制

@SpringBootApplication下注解有三个

**@SpringbootConfiguration** 以javaConfig的形式，将此类作为IOC的配置类

**@ComponentScan** 默认扫描类所在包下的所有类

**@AutoConfigurationPackage**。也就是说当SpringBoot应用启动时默认会将启动类所在的package作为自动配置的package。



**@EnableAutoConfiguration** 里面有一个@Import借助它 导入SpringFactoriesLoader到容器，利用

```
AutoConfigurationImportSelector
```

主要功能是从指定配置文件`META-INF/spring.factories`加载配置 里面存着很多全类名

mybatis 二级缓存

一级缓存是sqlsession 级别的默认开启，当时用同一个sqlsession时，如果先后执行同一个sql，会直接使用一级缓存

二级缓存是mapper级别的，而且多个sqlSession共享

设置方式，在配置文件 cacheEnabled = true 默认是开启的



执行器

- SIMPLE: 默认的执行器, 对每条sql进行预编译->设置参数->执行等操作
- BATCH: 批量执行器, 对相同sql进行一次预编译, 然后设置参数, 最后统一执行操作
- REUSE: REUSE 执行器会重用预处理语句（prepared statements

配置方式

1.1 局部设置
在获取sqlSession时设置, 需要注意的时, 如果选择的是批量执行器时, 需要手工提交事务.

// 获取指定执行器的sqlSession
SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH)

// 获取批量执行器时, 需要手动提交事务
sqlSession.commit();
1
2
3
4
5
1.2 全局配置
可在全局配置文件中配置, 但是笔者不推荐这种方式, 了解即可.

<settings>
    <setting name="defaultExecutorType" value="BATCH" />
</settings>

redis 缓存击穿 缓存穿透 缓存血崩



一：缓存穿透
缓存穿透：当发送请求时通过key去缓存查询，如果不存在对应的value，就应该去数据库查找。一些恶意的请求会故意查询不存在的key，而且需求量很大。如果发送一万个不存在key的请求，就会对后端系统造成很大的压力，数据库有可能会挂掉，这叫做缓存穿透。
解决方法：
A：缓存空对象：当发送了请求，通过不存在的key去查找值时，我们可以在缓存中去添加这个key，并且给这份key赋值为null，只要他去查找这个key时，直接给他返回一个null即可，当他第一次查询时，判断缓存没有就会去数据库查找，缓存就会台添加这个key，并且复制为null，第二次查询时就会查询缓存，不会再查询数据库，就可以避免这个问题，如果之后确实添加了这个key的值，也会将之前的值覆盖 。缺点就是这样做的话，如果发送了很多不存在的key，会给redis造成大量的空间浪费，也是治标不治本。
B：布隆过滤器：
布隆过滤器会隔一段时间扫描一次缓存和数据库，会将缓存和数据库共有的数据添加到布隆过滤器，当由请求过来时，会先进入布隆过滤器中进行查找，有的话返回数据，没有的话会到数据中查找

**缓存击穿：意思是缓存当中没有，而数据库有的数据，如果有98次请求的话，就会查询98次数据库，出现的了是并发问题。
原因：缓存中没有这个数据或者是这个数据刚刚达到过期时间失效了。
解决方法：添加分布式锁**

从这个代码中可以看出：如果我们有98次请求去查找这个key，当我们redisLock.lock(key)，开启分布式锁时，98次请求就会只进去一次请求，只有一个线程执行，查询缓存，如果缓存没有的话去数据库查找，然后给缓存添加数据，最后解锁，然后就会在进去一次请求，还是只有一个线程执行，此时缓存中已经有数据了，这个线程就会到缓存中去查找，后续的都一样，所以就会执行一次查询数据的方法，这样就解决了缓存穿透这个问题。
三：缓存雪崩
缓存雪崩：如果机器宕机，数据丢失，是一种雪崩，如果redis添加了100w的数据，在同一时刻40w数据同时失效，也是一种雪崩，意思是在同一时刻大量数据丢失就可以理解为雪崩。
解决办法
A：搭建高可用集群
B：设置过期时间错开，不要把100w数据的过期时间全部设置成一样的，把时间错开来。比如有的3天，有的10天这种的。

cloud 组件 及作用 机制

mysql 索引底层数据结构 以及建立索引



# kafka中的topic为什么要进行分区?

若没有分区，一个topic对应的消息集在分布式集群服务组中，就会分布不均匀，即可能导致某台服务器A记录当前topic的消息集很多，若此topic的消息压力很大的情况下，服务器A就可能导致压力很大，吞吐也容易导致瓶颈。

（1）***\*方便在集群中扩展\****，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；

（2）***\*可以提高并发\****，因为可以以Partition为单位读写了。







spring bean初始化过程





a24001





2021-04-01 11:58:49.410 [taskExecutor-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - Auto-commit of offsets 

{environ_day-1=OffsetAndMetadata{offset=244, metadata=''},

 environ_day-0=OffsetAndMetadata{offset=224, metadata=''},

 environ_day-2=OffsetAndMetadata{offset=228, metadata=''}} failed for group liantu:

 Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. 

You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.