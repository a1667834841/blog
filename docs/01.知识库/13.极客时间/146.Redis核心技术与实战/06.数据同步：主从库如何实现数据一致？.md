---
author: 蒋德钧
article: false
sidebar: true
tags: 
  - 极客时间
title: 数据同步：主从库如何实现数据一致？
date: 2022-10-18 11:09:52
permalink: /pages/5e6b76/
---
 
<span data-slate-object="text" data-key="3001"><span data-slate-leaf="true" data-offset-key="3001:0" data-first-offset="true"><span data-slate-string="true">你好，我是蒋德钧。</span></span></span>
<span data-slate-object="text" data-key="3003"><span data-slate-leaf="true" data-offset-key="3003:0" data-first-offset="true"><span data-slate-string="true">前两节课，我们学习了 AOF 和 RDB，如果 Redis 发生了宕机，它们可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而保证尽量少丢失数据，提升可靠性。</span></span></span>
<span data-slate-object="text" data-key="3005"><span data-slate-leaf="true" data-offset-key="3005:0" data-first-offset="true"><span data-slate-string="true">不过，即使用了这两种方法，也依然存在服务不可用的问题。比如说，我们在实际使用时只运行了一个 Redis 实例，那么，如果这个实例宕机了，它在恢复期间，是无法服务新来的数据存取请求的。</span></span></span>
<span data-slate-object="text" data-key="3007"><span data-slate-leaf="true" data-offset-key="3007:0" data-first-offset="true"><span data-slate-string="true">那我们总说的 Redis 具有高可靠性，又是什么意思呢？其实，这里有两层含义：一是</span></span></span><span data-slate-object="text" data-key="3008"><span data-slate-leaf="true" data-offset-key="3008:0" data-first-offset="true"><span class="se-412cbea8" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">数据尽量少丢失</span></span></span></span><span data-slate-object="text" data-key="3009"><span data-slate-leaf="true" data-offset-key="3009:0" data-first-offset="true"><span data-slate-string="true">，二是</span></span></span><span data-slate-object="text" data-key="3010"><span data-slate-leaf="true" data-offset-key="3010:0" data-first-offset="true"><span class="se-2af8e9d6" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">服务尽量少中断</span></span></span></span><span data-slate-object="text" data-key="3011"><span data-slate-leaf="true" data-offset-key="3011:0" data-first-offset="true"><span data-slate-string="true">。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是</span></span></span><span data-slate-object="text" data-key="3012"><span data-slate-leaf="true" data-offset-key="3012:0" data-first-offset="true"><span class="se-77f85d35" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">增加副本冗余量</span></span></span></span><span data-slate-object="text" data-key="3013"><span data-slate-leaf="true" data-offset-key="3013:0" data-first-offset="true"><span data-slate-string="true">，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。</span></span></span>
<span data-slate-object="text" data-key="3015"><span data-slate-leaf="true" data-offset-key="3015:0" data-first-offset="true"><span data-slate-string="true">多实例保存同一份数据，听起来好像很不错，但是，我们必须要考虑一个问题：这么多副本，它们之间的数据如何保持一致呢？数据读写操作可以发给所有的实例吗？</span></span></span>
<span data-slate-object="text" data-key="3017"><span data-slate-leaf="true" data-offset-key="3017:0" data-first-offset="true"><span data-slate-string="true">实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。</span></span></span>
- 读操作
- ：主库、从库都可以接收；
- 写操作
- ：首先到主库执行，然后，主库将写操作同步给从库。
![图片](https://static001.geekbang.org/resource/image/80/2f/809d6707404731f7e493b832aa573a2f.jpg)
<span data-slate-object="text" data-key="3027"><span data-slate-leaf="true" data-offset-key="3027:0" data-first-offset="true"><span data-slate-string="true">那么，为什么要采用读写分离的方式呢？</span></span></span>
<span data-slate-object="text" data-key="3029"><span data-slate-leaf="true" data-offset-key="3029:0" data-first-offset="true"><span data-slate-string="true">你可以设想一下，如果在上图中，不管是主库还是从库，都能接收客户端的写操作，那么，一个直接的问题就是：如果客户端对同一个数据（例如 k1）前后修改了三次，每一次的修改请求都发送到不同的实例上，在不同的实例上执行，那么，这个数据在这三个实例上的副本就不一致了（分别是 v1、v2 和 v3）。在读取这个数据的时候，就可能读取到旧的值。</span></span></span>
<span data-slate-object="text" data-key="3031"><span data-slate-leaf="true" data-offset-key="3031:0" data-first-offset="true"><span data-slate-string="true">如果我们非要保持这个数据在三个实例上一致，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销，当然是不太能接受的。</span></span></span>
<span data-slate-object="text" data-key="3033"><span data-slate-leaf="true" data-offset-key="3033:0" data-first-offset="true"><span data-slate-string="true">而主从库模式一旦采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个实例。主库有了最新的数据后，会同步给从库，这样，主从库的数据就是一致的。</span></span></span>
<span data-slate-object="text" data-key="3035"><span data-slate-leaf="true" data-offset-key="3035:0" data-first-offset="true"><span data-slate-string="true">那么，主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？这节课，我就和你聊聊主从库同步的原理，以及应对网络断连风险的方案。</span></span></span>
<span data-slate-object="text" data-key="3037"><span data-slate-leaf="true" data-offset-key="3037:0" data-first-offset="true"><span data-slate-string="true">好了，我们先来看看主从库间的第一次同步是如何进行的，这也是 Redis 实例建立主从库模式后的规定动作。</span></span></span>
## 主从库间如何进行第一次同步？
<span data-slate-object="text" data-key="3041"><span data-slate-leaf="true" data-offset-key="3041:0" data-first-offset="true"><span data-slate-string="true">当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</span></span></span>
<span data-slate-object="text" data-key="3043"><span data-slate-leaf="true" data-offset-key="3043:0" data-first-offset="true"><span data-slate-string="true">例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：</span></span></span>
```java 
replicaof  172.16.19.3  6379

 ``` 
<span data-slate-object="text" data-key="3048"><span data-slate-leaf="true" data-offset-key="3048:0" data-first-offset="true"><span data-slate-string="true">接下来，我们就要学习主从库间数据第一次同步的三个阶段了。你可以先看一下下面这张图，有个整体感知，接下来我再具体介绍。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/63/a1/63d18fd41efc9635e7e9105ce1c33da1.jpg)
<span data-slate-object="text" data-key="3051"><span data-slate-leaf="true" data-offset-key="3051:0" data-first-offset="true"><span data-slate-string="true">第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，</span></span></span><span data-slate-object="text" data-key="3052"><span data-slate-leaf="true" data-offset-key="3052:0" data-first-offset="true"><span class="se-948876d1" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了</span></span></span></span><span data-slate-object="text" data-key="3053"><span data-slate-leaf="true" data-offset-key="3053:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="3055"><span data-slate-leaf="true" data-offset-key="3055:0" data-first-offset="true"><span data-slate-string="true">具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了</span></span></span><span data-slate-object="text" data-key="3056"><span data-slate-leaf="true" data-offset-key="3056:0" data-first-offset="true"><span class="se-a02b116c" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">主库的 runID</span></span></span></span><span data-slate-object="text" data-key="3057"><span data-slate-leaf="true" data-offset-key="3057:0" data-first-offset="true"><span data-slate-string="true"> 和</span></span></span><span data-slate-object="text" data-key="3058"><span data-slate-leaf="true" data-offset-key="3058:0" data-first-offset="true"><span class="se-f5906946" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">复制进度 offset</span></span></span></span><span data-slate-object="text" data-key="3059"><span data-slate-leaf="true" data-offset-key="3059:0" data-first-offset="true"><span data-slate-string="true"> 两个参数。</span></span></span>
- runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。
- offset，此时设为 -1，表示第一次复制。
<span data-slate-object="text" data-key="3066"><span data-slate-leaf="true" data-offset-key="3066:0" data-first-offset="true"><span data-slate-string="true">主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。</span></span></span>
<span data-slate-object="text" data-key="3068"><span data-slate-leaf="true" data-offset-key="3068:0" data-first-offset="true"><span data-slate-string="true">这里有个地方需要注意，</span></span></span><span data-slate-object="text" data-key="3069"><span data-slate-leaf="true" data-offset-key="3069:0" data-first-offset="true"><span class="se-89afb9e4" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库</span></span></span></span><span data-slate-object="text" data-key="3070"><span data-slate-leaf="true" data-offset-key="3070:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="3072"><span data-slate-leaf="true" data-offset-key="3072:0" data-first-offset="true"><span data-slate-string="true">在第二阶段，</span></span></span><span data-slate-object="text" data-key="3073"><span data-slate-leaf="true" data-offset-key="3073:0" data-first-offset="true"><span class="se-769d0702" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载</span></span></span></span><span data-slate-object="text" data-key="3074"><span data-slate-leaf="true" data-offset-key="3074:0" data-first-offset="true"><span data-slate-string="true">。这个过程依赖于内存快照生成的 RDB 文件。</span></span></span>
<span data-slate-object="text" data-key="3076"><span data-slate-leaf="true" data-offset-key="3076:0" data-first-offset="true"><span data-slate-string="true">具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。</span></span></span>
<span data-slate-object="text" data-key="3078"><span data-slate-leaf="true" data-offset-key="3078:0" data-first-offset="true"><span data-slate-string="true">在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</span></span></span>
<span data-slate-object="text" data-key="3080"><span data-slate-leaf="true" data-offset-key="3080:0" data-first-offset="true"><span data-slate-string="true">最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</span></span></span>
## 主从级联模式分担全量复制时的主库压力
<span data-slate-object="text" data-key="3084"><span data-slate-leaf="true" data-offset-key="3084:0" data-first-offset="true"><span data-slate-string="true">通过分析主从库间第一次数据同步的过程，你可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。</span></span></span>
<span data-slate-object="text" data-key="3086"><span data-slate-leaf="true" data-offset-key="3086:0" data-first-offset="true"><span data-slate-string="true">如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？</span></span></span>
<span data-slate-object="text" data-key="3088"><span data-slate-leaf="true" data-offset-key="3088:0" data-first-offset="true"><span data-slate-string="true">其实是有的，这就是“主 - 从 - 从”模式。</span></span></span>
<span data-slate-object="text" data-key="3090"><span data-slate-leaf="true" data-offset-key="3090:0" data-first-offset="true"><span data-slate-string="true">在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以</span></span></span><span data-slate-object="text" data-key="3091"><span data-slate-leaf="true" data-offset-key="3091:0" data-first-offset="true"><span class="se-a7ba0419" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</span></span></span></span><span data-slate-object="text" data-key="3092"><span data-slate-leaf="true" data-offset-key="3092:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="3094"><span data-slate-leaf="true" data-offset-key="3094:0" data-first-offset="true"><span data-slate-string="true">简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。</span></span></span>
```java 
replicaof  所选从库的IP 6379

 ``` 
<span data-slate-object="text" data-key="3099"><span data-slate-leaf="true" data-offset-key="3099:0" data-first-offset="true"><span data-slate-string="true">这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：</span></span></span>
![图片](https://static001.geekbang.org/resource/image/40/45/403c2ab725dca8d44439f8994959af45.jpg)
<span data-slate-object="text" data-key="3102"><span data-slate-leaf="true" data-offset-key="3102:0" data-first-offset="true"><span data-slate-string="true">好了，到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 - 从”模式分担主库压力的方式。那么，一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为</span></span></span><span data-slate-object="text" data-key="3103"><span data-slate-leaf="true" data-offset-key="3103:0" data-first-offset="true"><span class="se-6258df47" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">基于长连接的命令传播</span></span></span></span><span data-slate-object="text" data-key="3104"><span data-slate-leaf="true" data-offset-key="3104:0" data-first-offset="true"><span data-slate-string="true">，可以避免频繁建立连接的开销。</span></span></span>
<span data-slate-object="text" data-key="3106"><span data-slate-leaf="true" data-offset-key="3106:0" data-first-offset="true"><span data-slate-string="true">听上去好像很简单，但不可忽视的是，这个过程中存在着风险点，最常见的就是</span></span></span><span data-slate-object="text" data-key="3107"><span data-slate-leaf="true" data-offset-key="3107:0" data-first-offset="true"><span class="se-e6d81a24" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">网络断连或阻塞</span></span></span></span><span data-slate-object="text" data-key="3108"><span data-slate-leaf="true" data-offset-key="3108:0" data-first-offset="true"><span data-slate-string="true">。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致了，客户端就可能从从库读到旧数据。</span></span></span>
<span data-slate-object="text" data-key="3110"><span data-slate-leaf="true" data-offset-key="3110:0" data-first-offset="true"><span data-slate-string="true">接下来，我们就来聊聊网络断连后的解决办法。</span></span></span>
## 主从库间网络断了怎么办？
<span data-slate-object="text" data-key="3114"><span data-slate-leaf="true" data-offset-key="3114:0" data-first-offset="true"><span data-slate-string="true">在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。</span></span></span>
<span data-slate-object="text" data-key="3116"><span data-slate-leaf="true" data-offset-key="3116:0" data-first-offset="true"><span data-slate-string="true">从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。</span></span></span>
<span data-slate-object="text" data-key="3118"><span data-slate-leaf="true" data-offset-key="3118:0" data-first-offset="true"><span data-slate-string="true">那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥妙就在于 repl_backlog_buffer 这个缓冲区。我们先来看下它是如何用于增量命令的同步的。</span></span></span>
<span data-slate-object="text" data-key="3120"><span data-slate-leaf="true" data-offset-key="3120:0" data-first-offset="true"><span data-slate-string="true">当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。</span></span></span>
<span data-slate-object="text" data-key="3122"><span data-slate-leaf="true" data-offset-key="3122:0" data-first-offset="true"><span data-slate-string="true">repl_backlog_buffer 是一个环形缓冲区，</span></span></span><span data-slate-object="text" data-key="3123"><span data-slate-leaf="true" data-offset-key="3123:0" data-first-offset="true"><span class="se-49a397e4" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">主库会记录自己写到的位置，从库则会记录自己已经读到的位置</span></span></span></span><span data-slate-object="text" data-key="3124"><span data-slate-leaf="true" data-offset-key="3124:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="3126"><span data-slate-leaf="true" data-offset-key="3126:0" data-first-offset="true"><span data-slate-string="true">刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。</span></span></span>
<span data-slate-object="text" data-key="3128"><span data-slate-leaf="true" data-offset-key="3128:0" data-first-offset="true"><span data-slate-string="true">同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/13/37/13f26570a1b90549e6171ea24554b737.jpg)
<span data-slate-object="text" data-key="3131"><span data-slate-leaf="true" data-offset-key="3131:0" data-first-offset="true"><span data-slate-string="true">主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。</span></span></span>
<span data-slate-object="text" data-key="3133"><span data-slate-leaf="true" data-offset-key="3133:0" data-first-offset="true"><span data-slate-string="true">在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。</span></span></span>
<span data-slate-object="text" data-key="3135"><span data-slate-leaf="true" data-offset-key="3135:0" data-first-offset="true"><span data-slate-string="true">就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</span></span></span>
<span data-slate-object="text" data-key="3137"><span data-slate-leaf="true" data-offset-key="3137:0" data-first-offset="true"><span data-slate-string="true">说到这里，我们再借助一张图，回顾下增量复制的流程。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/20/16/20e233bd30c3dacb0221yy0c77780b16.jpg)
<span data-slate-object="text" data-key="3140"><span data-slate-leaf="true" data-offset-key="3140:0" data-first-offset="true"><span data-slate-string="true">不过，有一个地方我要强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。</span></span></span><span data-slate-object="text" data-key="3141"><span data-slate-leaf="true" data-offset-key="3141:0" data-first-offset="true"><span class="se-b605c62c" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致</span></span></span></span><span data-slate-object="text" data-key="3142"><span data-slate-leaf="true" data-offset-key="3142:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="3144"><span data-slate-leaf="true" data-offset-key="3144:0" data-first-offset="true"><span data-slate-string="true">因此，我们要想办法避免这一情况，一般而言，我们可以调整 </span></span></span><span data-slate-object="text" data-key="3145"><span data-slate-leaf="true" data-offset-key="3145:0" data-first-offset="true"><span class="se-4e403157" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">repl_backlog_size</span></span></span></span><span data-slate-object="text" data-key="3146"><span data-slate-leaf="true" data-offset-key="3146:0" data-first-offset="true"><span data-slate-string="true"> 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。</span></span></span>
<span data-slate-object="text" data-key="3148"><span data-slate-leaf="true" data-offset-key="3148:0" data-first-offset="true"><span data-slate-string="true">举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。</span></span></span>
<span data-slate-object="text" data-key="3150"><span data-slate-leaf="true" data-offset-key="3150:0" data-first-offset="true"><span data-slate-string="true">这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致。</span></span></span>
<span data-slate-object="text" data-key="3152"><span data-slate-leaf="true" data-offset-key="3152:0" data-first-offset="true"><span data-slate-string="true">针对这种情况，一方面，你可以根据 Redis 所在服务器的内存资源再适当增加 repl_backlog_size 值，比如说设置成缓冲空间大小的 4 倍，另一方面，你可以考虑使用切片集群来分担单个主库的请求压力。关于切片集群，我会在第 9 讲具体介绍。</span></span></span>
## 小结
<span data-slate-object="text" data-key="3156"><span data-slate-leaf="true" data-offset-key="3156:0" data-first-offset="true"><span data-slate-string="true">这节课，我们一起学习了 Redis 的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。</span></span></span>
<span data-slate-object="text" data-key="3158"><span data-slate-leaf="true" data-offset-key="3158:0" data-first-offset="true"><span data-slate-string="true">全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：</span></span></span><span data-slate-object="text" data-key="3159"><span data-slate-leaf="true" data-offset-key="3159:0" data-first-offset="true"><span class="se-a2179f5c" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">一个 Redis 实例的数据库不要太大</span></span></span></span><span data-slate-object="text" data-key="3160"><span data-slate-leaf="true" data-offset-key="3160:0" data-first-offset="true"><span data-slate-string="true">，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。</span></span></span>
<span data-slate-object="text" data-key="3162"><span data-slate-leaf="true" data-offset-key="3162:0" data-first-offset="true"><span data-slate-string="true">长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。我特别建议你留意一下 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。</span></span></span>
<span data-slate-object="text" data-key="3164"><span data-slate-leaf="true" data-offset-key="3164:0" data-first-offset="true"><span data-slate-string="true">不过，主从库模式使用读写分离虽然避免了同时写多个实例带来的数据不一致问题，但是还面临主库故障的潜在风险。主库故障了从库该怎么办，数据还能保持一致吗，Redis 还能正常提供服务吗？在接下来的两节课里，我会和你具体聊聊主库故障后，保证服务可靠性的解决方案。</span></span></span>
## 每课一问
<span data-slate-object="text" data-key="3168"><span data-slate-leaf="true" data-offset-key="3168:0" data-first-offset="true"><span data-slate-string="true">按照惯例，我给你提一个小问题。这节课，我提到，主从库间的数据复制同步使用的是 RDB 文件，前面我们学习过，AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么，为什么主从库间的复制不使用 AOF 呢？</span></span></span>
<span data-slate-object="text" data-key="3170"><span data-slate-leaf="true" data-offset-key="3170:0" data-first-offset="true"><span data-slate-string="true">好了，这节课就到这里，如果你觉得有收获，欢迎你帮我把今天的内容分享给你的朋友。</span></span></span>
精选评论 
 ------- 
 ::: details 
<a style='font-size:1.5em;font-weight:bold'>Kaito</a> 


 ```java 
主从全量同步使用RDB而不使用AOF的原因：

1、RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。

2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。

另外，需要指出老师文章的错误：“当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。”

1、主从库连接都断开了，哪里来replication buffer呢？

2、应该不是“主从库断连后”主库才把写操作写入repl_backlog_buffer，只要有从库存在，这个repl_backlog_buffer就会存在。主库的所有写命令除了传播给从库之外，都会在这个repl_backlog_buffer中记录一份，缓存起来，只有预先缓存了这些命令，当从库断连后，从库重新发送psync $master_runid $offset，主库才能通过$offset在repl_backlog_buffer中找到从库断开的位置，只发送$offset之后的增量数据给从库即可。

有同学对repl_backlog_buffer和replication buffer理解比较混淆，我大概解释一下：

1、repl_backlog_buffer：就是上面我解释到的，它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。

2、replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。

3、再延伸一下，既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了client-output-buffer-limit参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Geek_121747</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>Darren</a> 


 ```java 
上一条评论有误，已经删除，请通过本条评论

repl_backlog_size这个参数很重要，因为如果满了，就需要重新全量复制，默认是1M，所以之前网上就流传1个段子，如果一个公司说自己体量如何大，技术多么牛，要是repl_backlog_size参数是默认值，基本可以认为要不业务体量吹牛逼了，要不就没有真正的技术牛人。

主从复制的另一种方式：基于硬盘和无盘复制
可以通过这个参数设置
repl-diskless-sync
复制集同步策略：磁盘或者socket
新slave连接或者老slave重新连接时候不能只接收不同，得做一个全同步。需要一个新的RDB文件dump出来，然后从master传到slave。可以有两种情况：
 1）基于硬盘（disk-backed）：master创建一个新进程dump RDB，完事儿之后由父进程（即主进程）增量传给slaves。
 2）基于socket（diskless）：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。

当基于 disk-backed 复制时，当 RDB 文件生成完毕，多个 replicas 通过排队来同步 RDB 文件。

当基于diskless的时候，master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了。否则就可以一起传。适用于disk较慢，并且网络较快的时候，可以用diskless。（默认用disk-based）


回答下课后问题：
    1、RDB读取快，这样从库可以尽快完成RDB的读取，然后入去消费replication buffer的数据。如果是AOF的话，AOF体积大，读取慢，需要更大的replication buffer，如果一个主节点的从节点多的话，就需要更大的内存去处理；
    2、AOF文件是append追加模式，同时读写需要考虑并发安全问题，并且AOF是文本文件，体积较大，浪费网络带宽。

最后问老师个问题哈，就是bgsave生成的rdb文件什么时候“过期”，或者有过期的说法吗？比如我2个从节点执行replicaof（或者slaveof），主节点是同一个，这中情况下，rdb生成1次还是2次？
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>test</a> 


 ```java 
课后题：aof比rdb大，rdb加载起来比aof快。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Monday</a> 


 ```java 
repl_backlog_buffer是以从库为粒度保存的吧，也就说在一主多从的情况下，主会分别保存多每个从库的处理位置吧。
思考题：
1、rdb比aof通常情况下会大些，
2、传播起来更耗带宽等资源
3、从库恢复更耗时间

```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Jackey</a> 


 ```java 
印象中Redis在repl_backlog_buffer写满了之后会触发一次全量复制，以此来保证被覆盖的数据不丢失。不知道对不对
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>tt</a> 


 ```java 
我觉得之所以主从库间的数据复制同步使用的是 RDB 文件，是因为主从复制要解决的是不同节点之间状态的一致性问题，RDB文件的内容正好是某一个时间点主库的状态

AOF文件则不同，其内容本质上是操作而不是状态，内容存在大量冗余。主从复制本质上是一个最终一致性的过程，为了减少不一致的时间窗口的大小，采用RDB文件是最合适的。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>王聪</a> 


 ```java 
看了课程内容,不看评论绝对是一种损失
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Kyushu</a> 


 ```java 
除了从库命令读取比较慢以外，如果网络断连再恢复造成了repl_backlog_buffer的覆盖也就永远的不一致了吧，这样也只能通过调大他的值决定吗
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Frank</a> 


 ```java 
1. 相同数据下，AOF 文件比 RDB 更大，因此需要的网络带宽更多；
2. 在恢复数据时，使用RDB更快。
3. 如果使用AOF文件来同步相对来说丢的数据更少，但是不表示不丢数据。即也需要第三个阶段来保证数据的一致性。因此相对来说使用RDB开销更小些。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>yyl</a> 


 ```java 
解答：主从同步采用RDB的原因是由于采用RDB，从节点恢复效率更好，能够更快地对外提供服务，分担主节点的读压力。
如果采用AOF日志，从节点需要逐条执行命令，恢复效率低
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>啦啦啦</a> 


 ```java 
从库在执行 replication buffer里面的命令的时候，这时候主库不又会产生新的数据了吗？这样下去不就没完没了了吗
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>醉、随风🙄 🙄</a> 


 ```java 
我有个问题，为什么一定要同时存在repl_backlog_buffer和replication buffer两个缓冲区，而且repl_backlog_buffer确要定义成环形的。我觉得是否可以定义成一个链表，然后主库的offset与从库的offset都指向链表中某个元素，redis定时清理从库offset之前的数据，这样不是做到了既能增量同步，也不用担心因为并发过大造成的同步数据丢失。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>猿人谷</a> 


 ```java 
补充一个知识点：主从模式下，Redis能否读到过期键？
当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期键的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>那时刻</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>yayiyaya</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>阿卡牛</a> 


 ```java 
主库和从库可以布署在不同的地理位置吗
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>QFY</a> 


 ```java 
课后题：
aof记录的是命令，如果是首次主从全量复制，而且如果aof文件还没被重写会存在对一个key的反复操作，那么效率会比较低

疑问：
【repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置】针对这一句，这个repl_backlog_buffer是在主库上面，但是他同时要记录master_repl_offset和slave_repl_offset，这个slave_repl_offset是每个从库记录一个还是共用一个？如果是共用一个，那如果有两个从库正在恢复，一个正常恢复把slave_repl_offset往前推了，另一个从库在恢复的过程中又断了，但是再恢复的时候slave_repl_offset已经往前推了，中间就有一部分数据丢失了，这个情况该怎么办了（这个情况可能有点极端）

```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>tt</a> 


 ```java 
老师，还有一个问题，主从同步时，生成RDB快照是由bgsave进程完成的，那主库发送RDB文件内容和从库接收数据各是有哪些线程完成的呢？也是主线程么？
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Mr.蜜</a> 


 ```java 
我有一个疑问，环形缓冲期再大，也会出问题，那么如果遇到这类问题，导致数据不同步怎么处理？比方说，一个从库长断网以后，长时间没有联网处理。
```
 ----- 
:::