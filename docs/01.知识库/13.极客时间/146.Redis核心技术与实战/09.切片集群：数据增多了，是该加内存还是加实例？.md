--- 
author: 蒋德钧
article: false
sidebar: true
tags: 
  - 极客时间 
--- 
<span data-slate-object="text" data-key="1165"><span data-slate-leaf="true" data-offset-key="1165:0" data-first-offset="true"><span data-slate-string="true">你好，我是蒋德钧。今天我们来学习切片集群。</span></span></span>
<span data-slate-object="text" data-key="1167"><span data-slate-leaf="true" data-offset-key="1167:0" data-first-offset="true"><span data-slate-string="true">我曾遇到过这么一个需求：要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B，为了能快速部署并对外提供服务，我们采用云主机来运行 Redis 实例，那么，该如何选择云主机的内存容量呢？</span></span></span>
<span data-slate-object="text" data-key="1169"><span data-slate-leaf="true" data-offset-key="1169:0" data-first-offset="true"><span data-slate-string="true">我粗略地计算了一下，这些键值对所占的内存空间大约是 25GB（5000 万 *512B）。所以，当时，我想到的第一个方案就是：选择一台 32GB 内存的云主机来部署 Redis。因为 32GB 的内存能保存所有数据，而且还留有 7GB，可以保证系统的正常运行。同时，我还采用 RDB 对数据做持久化，以确保 Redis 实例故障后，还能从 RDB 恢复数据。</span></span></span>
<span data-slate-object="text" data-key="1171"><span data-slate-leaf="true" data-offset-key="1171:0" data-first-offset="true"><span data-slate-string="true">但是，在使用的过程中，我发现，Redis 的响应有时会非常慢。后来，我们使用 INFO 命令查看 Redis 的 latest_fork_usec 指标值（表示最近一次 fork 的耗时），结果显示这个指标值特别高，快到秒级别了。</span></span></span>
<span data-slate-object="text" data-key="1173"><span data-slate-leaf="true" data-offset-key="1173:0" data-first-offset="true"><span data-slate-string="true">这跟 Redis 的持久化机制有关系。在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致 Redis 响应变慢了。</span></span></span>
<span data-slate-object="text" data-key="1175"><span data-slate-leaf="true" data-offset-key="1175:0" data-first-offset="true"><span data-slate-string="true">看来，第一个方案显然是不可行的，我们必须要寻找其他的方案。这个时候，我们注意到了 Redis 的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 Redis 主线程的阻塞影响较小。</span></span></span>
<span data-slate-object="text" data-key="1177"><span data-slate-leaf="true" data-offset-key="1177:0" data-first-offset="true"><span data-slate-string="true">切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把 25GB 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5GB 数据。如下图所示：</span></span></span>
![图片](https://static001.geekbang.org/resource/image/79/26/793251ca784yyf6ac37fe46389094b26.jpg)
<span data-slate-object="text" data-key="1180"><span data-slate-leaf="true" data-offset-key="1180:0" data-first-offset="true"><span data-slate-string="true">那么，在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。</span></span></span>
<span data-slate-object="text" data-key="1182"><span data-slate-leaf="true" data-offset-key="1182:0" data-first-offset="true"><span data-slate-string="true">在实际应用 Redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。这节课，我们就来学习一下。</span></span></span>
## 如何保存更多数据？
<span data-slate-object="text" data-key="1186"><span data-slate-leaf="true" data-offset-key="1186:0" data-first-offset="true"><span data-slate-string="true">在刚刚的案例里，为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着 Redis 应对数据量增多的两种方案：纵向扩展（scale up）和横向扩展（scale out）。</span></span></span>
- 纵向扩展
- ：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。
- 横向扩展
- ：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例。
![图片](https://static001.geekbang.org/resource/image/7a/1a/7a512fec7eba789c6d098b834929701a.jpg)
<span data-slate-object="text" data-key="1196"><span data-slate-leaf="true" data-offset-key="1196:0" data-first-offset="true"><span data-slate-string="true">那么，这两种方式的优缺点分别是什么呢？</span></span></span>
<span data-slate-object="text" data-key="1198"><span data-slate-leaf="true" data-offset-key="1198:0" data-first-offset="true"><span data-slate-string="true">首先，纵向扩展的好处是，</span></span></span><span data-slate-object="text" data-key="1199"><span data-slate-leaf="true" data-offset-key="1199:0" data-first-offset="true"><span class="se-b78cee7e" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">实施起来简单、直接</span></span></span></span><span data-slate-object="text" data-key="1200"><span data-slate-leaf="true" data-offset-key="1200:0" data-first-offset="true"><span data-slate-string="true">。不过，这个方案也面临两个潜在的问题。</span></span></span>
<span data-slate-object="text" data-key="1202"><span data-slate-leaf="true" data-offset-key="1202:0" data-first-offset="true"><span data-slate-string="true">第一个问题是，当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（比如刚刚的例子中的情况）。不过，如果你不要求持久化保存 Redis 数据，那么，纵向扩展会是一个不错的选择。</span></span></span>
<span data-slate-object="text" data-key="1204"><span data-slate-leaf="true" data-offset-key="1204:0" data-first-offset="true"><span data-slate-string="true">不过，这时，你还要面对第二个问题：</span></span></span><span data-slate-object="text" data-key="1205"><span data-slate-leaf="true" data-offset-key="1205:0" data-first-offset="true"><span class="se-5e6ff3c2" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">纵向扩展会受到硬件和成本的限制</span></span></span></span><span data-slate-object="text" data-key="1206"><span data-slate-leaf="true" data-offset-key="1206:0" data-first-offset="true"><span data-slate-string="true">。这很容易理解，毕竟，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，就会面临硬件容量和成本上的限制了。</span></span></span>
<span data-slate-object="text" data-key="1208"><span data-slate-leaf="true" data-offset-key="1208:0" data-first-offset="true"><span data-slate-string="true">与纵向扩展相比，横向扩展是一个扩展性更好的方案。这是因为，要想保存更多的数据，采用这种方案的话，只用增加 Redis 的实例个数就行了，不用担心单个实例的硬件和成本限制。</span></span></span><span data-slate-object="text" data-key="1209"><span data-slate-leaf="true" data-offset-key="1209:0" data-first-offset="true"><span class="se-6f5226e5" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择</span></span></span></span><span data-slate-object="text" data-key="1210"><span data-slate-leaf="true" data-offset-key="1210:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="1212"><span data-slate-leaf="true" data-offset-key="1212:0" data-first-offset="true"><span data-slate-string="true">不过，在只使用单个实例的时候，数据存在哪儿，客户端访问哪儿，都是非常明确的，但是，切片集群不可避免地涉及到多个实例的分布式管理问题。要想把切片集群用起来，我们就需要解决两大问题：</span></span></span>
- 数据切片后，在多个实例之间如何分布？
- 客户端怎么确定想要访问的数据在哪个实例上？
<span data-slate-object="text" data-key="1219"><span data-slate-leaf="true" data-offset-key="1219:0" data-first-offset="true"><span data-slate-string="true">接下来，我们就一个个地解决。</span></span></span>
## 数据切片和实例的对应分布关系
<span data-slate-object="text" data-key="1223"><span data-slate-leaf="true" data-offset-key="1223:0" data-first-offset="true"><span data-slate-string="true">在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的 Redis Cluster 方案有关了。不过，我们要先弄明白切片集群和 Redis Cluster 的联系与区别。</span></span></span>
<span data-slate-object="text" data-key="1225"><span data-slate-leaf="true" data-offset-key="1225:0" data-first-offset="true"><span data-slate-string="true">实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。</span></span></span>
<span data-slate-object="text" data-key="1227"><span data-slate-leaf="true" data-offset-key="1227:0" data-first-offset="true"><span data-slate-string="true">具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</span></span></span>
<span data-slate-object="text" data-key="1229"><span data-slate-leaf="true" data-offset-key="1229:0" data-first-offset="true"><span data-slate-string="true">具体的映射过程分为两大步：首先根据键值对的 key，按照</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="1230" class="se-b5727c32 se-d1234f97"><span data-slate-object="text" data-key="1231"><span data-slate-leaf="true" data-offset-key="1231:0" data-first-offset="true"><span data-slate-string="true">CRC16 算法</span></span></span></a><span data-slate-object="text" data-key="1232"><span data-slate-leaf="true" data-offset-key="1232:0" data-first-offset="true"><span data-slate-string="true">计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。关于 CRC16 算法，不是这节课的重点，你简单看下链接中的资料就可以了。</span></span></span>
<span data-slate-object="text" data-key="1234"><span data-slate-leaf="true" data-offset-key="1234:0" data-first-offset="true"><span data-slate-string="true">那么，这些哈希槽又是如何被映射到具体的 Redis 实例上的呢？</span></span></span>
<span data-slate-object="text" data-key="1236"><span data-slate-leaf="true" data-offset-key="1236:0" data-first-offset="true"><span data-slate-string="true">我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。</span></span></span>
<span data-slate-object="text" data-key="1238"><span data-slate-leaf="true" data-offset-key="1238:0" data-first-offset="true"><span data-slate-string="true">当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。</span></span></span>
<span data-slate-object="text" data-key="1240"><span data-slate-leaf="true" data-offset-key="1240:0" data-first-offset="true"><span data-slate-string="true">举个例子，假设集群中不同 Redis 实例的内存大小配置不一，如果把哈希槽均分在各个实例上，在保存相同数量的键值对时，和内存大的实例相比，内存小的实例就会有更大的容量压力。遇到这种情况时，你可以根据不同实例的资源配置情况，使用 cluster addslots 命令手动分配哈希槽。</span></span></span>
<span data-slate-object="text" data-key="1242"><span data-slate-leaf="true" data-offset-key="1242:0" data-first-offset="true"><span data-slate-string="true">为了便于你理解，我画一张示意图来解释一下，数据、哈希槽、实例这三者的映射分布情况。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/7d/ab/7d070c8b19730b308bfaabbe82c2f1ab.jpg)
<span data-slate-object="text" data-key="1245"><span data-slate-leaf="true" data-offset-key="1245:0" data-first-offset="true"><span data-slate-string="true">示意图中的切片集群一共有 3 个实例，同时假设有 5 个哈希槽，我们首先可以通过下面的命令手动分配哈希槽：实例 1 保存哈希槽 0 和 1，实例 2 保存哈希槽 2 和 3，实例 3 保存哈希槽 4。</span></span></span>
```java 
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1
redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3
redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4

 ``` 
<span data-slate-object="text" data-key="1254"><span data-slate-leaf="true" data-offset-key="1254:0" data-first-offset="true"><span data-slate-string="true">在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 5 取模，再根据各自的模数结果，就可以被映射到对应的实例 1 和实例 3 上了。</span></span></span>
<span data-slate-object="text" data-key="1256"><span data-slate-leaf="true" data-offset-key="1256:0" data-first-offset="true"><span data-slate-string="true">另外，我再给你一个小提醒，</span></span></span><span data-slate-object="text" data-key="1257"><span data-slate-leaf="true" data-offset-key="1257:0" data-first-offset="true"><span class="se-5cfd0b2a" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作</span></span></span></span><span data-slate-object="text" data-key="1258"><span data-slate-leaf="true" data-offset-key="1258:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span>
<span data-slate-object="text" data-key="1260"><span data-slate-leaf="true" data-offset-key="1260:0" data-first-offset="true"><span data-slate-string="true">好了，通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽再到实例的分配。但是，即使实例有了哈希槽的映射信息，客户端又是怎么知道要访问的数据在哪个实例上呢？接下来，我就来和你聊聊。</span></span></span>
## 客户端如何定位数据？
<span data-slate-object="text" data-key="1264"><span data-slate-leaf="true" data-offset-key="1264:0" data-first-offset="true"><span data-slate-string="true">在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，还需要知道哈希槽分布在哪个实例上。</span></span></span>
<span data-slate-object="text" data-key="1266"><span data-slate-leaf="true" data-offset-key="1266:0" data-first-offset="true"><span data-slate-string="true">一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。</span></span></span>
<span data-slate-object="text" data-key="1268"><span data-slate-leaf="true" data-offset-key="1268:0" data-first-offset="true"><span data-slate-string="true">那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</span></span></span>
<span data-slate-object="text" data-key="1270"><span data-slate-leaf="true" data-offset-key="1270:0" data-first-offset="true"><span data-slate-string="true">客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</span></span></span>
<span data-slate-object="text" data-key="1272"><span data-slate-leaf="true" data-offset-key="1272:0" data-first-offset="true"><span data-slate-string="true">但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：</span></span></span>
- 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。
<span data-slate-object="text" data-key="1279"><span data-slate-leaf="true" data-offset-key="1279:0" data-first-offset="true"><span data-slate-string="true">此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？</span></span></span>
<span data-slate-object="text" data-key="1281"><span data-slate-leaf="true" data-offset-key="1281:0" data-first-offset="true"><span data-slate-string="true">Redis Cluster 方案提供了一种</span></span></span><span data-slate-object="text" data-key="1282"><span data-slate-leaf="true" data-offset-key="1282:0" data-first-offset="true"><span class="se-9b1d1864" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">重定向机制，</span></span></span></span><span data-slate-object="text" data-key="1283"><span data-slate-leaf="true" data-offset-key="1283:0" data-first-offset="true"><span data-slate-string="true">所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。</span></span></span>
<span data-slate-object="text" data-key="1285"><span data-slate-leaf="true" data-offset-key="1285:0" data-first-offset="true"><span data-slate-string="true">那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。</span></span></span>
```java 
GET hello:key
(error) MOVED 13320 172.16.19.5:6379

 ``` 
<span data-slate-object="text" data-key="1292"><span data-slate-leaf="true" data-offset-key="1292:0" data-first-offset="true"><span data-slate-string="true">其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。</span></span></span>
<span data-slate-object="text" data-key="1294"><span data-slate-leaf="true" data-offset-key="1294:0" data-first-offset="true"><span data-slate-string="true">我画一张图来说明一下，MOVED 重定向命令的使用方法。可以看到，由于负载均衡，Slot  2 中的数据已经从实例 2 迁移到了实例 3，但是，客户端缓存仍然记录着“Slot 2 在实例 2”的信息，所以会给实例 2 发送命令。实例 2 给客户端返回一条 MOVED 命令，把 Slot  2 的最新位置（也就是在实例 3 上），返回给客户端，客户端就会再次向实例 3 发送请求，同时还会更新本地缓存，把 Slot  2 与实例的对应关系更新过来。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/35/09/350abedefcdbc39d6a8a8f1874eb0809.jpg)
<span data-slate-object="text" data-key="1297"><span data-slate-leaf="true" data-offset-key="1297:0" data-first-offset="true"><span data-slate-string="true">需要注意的是，在上图中，当客户端给实例 2 发送命令时，Slot 2 中的数据已经全部迁移到了实例 3。在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：</span></span></span>
```java 
GET hello:key
(error) ASK 13320 172.16.19.5:6379

 ``` 
<span data-slate-object="text" data-key="1304"><span data-slate-leaf="true" data-offset-key="1304:0" data-first-offset="true"><span data-slate-string="true">这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。</span></span></span>
<span data-slate-object="text" data-key="1306"><span data-slate-leaf="true" data-offset-key="1306:0" data-first-offset="true"><span data-slate-string="true">看起来好像有点复杂，我再借助图片来解释一下。</span></span></span>
<span data-slate-object="text" data-key="1308"><span data-slate-leaf="true" data-offset-key="1308:0" data-first-offset="true"><span data-slate-string="true">在下图中，Slot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和 key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ASK 命令。</span></span></span>
<span data-slate-object="text" data-key="1310"><span data-slate-leaf="true" data-offset-key="1310:0" data-first-offset="true"><span data-slate-string="true">ASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。</span></span></span>
![图片](https://static001.geekbang.org/resource/image/e9/b0/e93ae7f4edf30724d58bf68yy714eeb0.jpg)
<span data-slate-object="text" data-key="1313"><span data-slate-leaf="true" data-offset-key="1313:0" data-first-offset="true"><span data-slate-string="true">和 MOVED 命令不同，</span></span></span><span data-slate-object="text" data-key="1314"><span data-slate-leaf="true" data-offset-key="1314:0" data-first-offset="true"><span class="se-7fa35b29" data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">ASK 命令并不会更新客户端缓存的哈希槽分配信息</span></span></span></span><span data-slate-object="text" data-key="1315"><span data-slate-leaf="true" data-offset-key="1315:0" data-first-offset="true"><span data-slate-string="true">。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。</span></span></span>
## 小结
<span data-slate-object="text" data-key="1319"><span data-slate-leaf="true" data-offset-key="1319:0" data-first-offset="true"><span data-slate-string="true">这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。</span></span></span>
<span data-slate-object="text" data-key="1321"><span data-slate-leaf="true" data-offset-key="1321:0" data-first-offset="true"><span data-slate-string="true">在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。Redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。</span></span></span>
<span data-slate-object="text" data-key="1323"><span data-slate-leaf="true" data-offset-key="1323:0" data-first-offset="true"><span data-slate-string="true">另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了 MOVED 和 ASK 命令，你就不会为这类报错而头疼了。</span></span></span>
<span data-slate-object="text" data-key="1325"><span data-slate-leaf="true" data-offset-key="1325:0" data-first-offset="true"><span data-slate-string="true">我刚刚说过，在 Redis 3.0 之前，Redis 官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 ShardedJedis，基于代理的 Codis、Twemproxy 等。这些方案的应用早于 Redis Cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。</span></span></span>
## 每课一问
<span data-slate-object="text" data-key="1329"><span data-slate-leaf="true" data-offset-key="1329:0" data-first-offset="true"><span data-slate-string="true">按照惯例，给你提一个小问题：Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？</span></span></span>
<span data-slate-object="text" data-key="1331"><span data-slate-leaf="true" data-offset-key="1331:0" data-first-offset="true"><span data-slate-string="true">欢迎你在留言区畅所欲言，如果你觉得有收获，也希望你能帮我把今天的内容分享给你的朋友，帮助更多人解决切片集群的问题。</span></span></span>
精选评论 
 ------- 
 ::: details 
<a style='font-size:1.5em;font-weight:bold'>Kaito</a> 


 ```java 
Redis Cluster不采用把key直接映射到实例的方式，而采用哈希槽的方式原因：

1、整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。

2、Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。

3、当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。

4、而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。

5、当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。

另外，我想补充一下Redis集群相关的知识，以及我的理解：

Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。

1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。

Redis Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。

其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。

2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。

Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？

Redis Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。

除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。

Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Darren</a> 


 ```java 
我认为有以下几点：
1、存在表的话，存在单点问题，即使部署多份，存在数据一致性问题，提高了复杂度；
2、即使解决了第一个问题，但是Redis主打的是快，表的读写并发问题处理；
3、key对应的是实例，对应关系粒度太大；

4、用key做hash避免依赖别的功能或者服务，提供了整体的内聚性；
5、在做Redis集群，为了数据分配均匀，进行一致性哈希的时候，虚拟节点和真实节点之间还有对应关系，存在多级映射关系，增加了耗时，影响Redis主线程的执行速度。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>小宇子2B</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>Monday</a> 


 ```java 
思考题：
1、使用CRC这个hash函数原因
1）hash从查询slot的时间复杂度上讲，CRC为O(1)；存表（理解为有序数组或跳表），再快也就是O(Log n)
2）hash从存储映射关系的空间复杂度上讲，CRC为O(1)；存表，至少也得O(n)，若是跳表还得存额外的索引

另外我有两个问题咨询下老师，望答复，谢谢！
1、Redis切片集群使用CRC这个hash函数先获取到具体的slot，然后在具体的slot中，是不是再通过另一个hash函数访问Key对应的值？类似于Java结构：HashMap<String, HashMap<String,Object>>
2、Redis的slot数量为什么是16384=2^14个，如果用2B来存长度也是2^16=65536个啊？


```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>优秀的吉吉国王</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>test</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>yyl</a> 


 ```java 
解答：
1. 引入哈希槽，将key的分布与具体的Redis实例解耦，有利于Redis数据的均衡分布。
2. 不采用哈希槽的话，Redis实例的扩容和缩容，需要针对无规则的key进行处理，实现数据迁移。此外，需要引入负载均衡中间件来协调各个Redis实例的均衡响应，确保数据的均匀分布；中间件需要保存key的分布状态，保证key的查询能够得到响应。
增加了Redis系统的复杂性 与 可维护性。

看到问题后的第一反应，理解不够深刻，讲述不够清楚。贵在思考啦😜
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Vincent</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>扩散性百万咸面包</a> 


 ```java 
隔壁分布式数据库也讲到了分片，但是它里面提到现代的分布式数据库实现分片基本都是Range-based的，能够实现分片的动态调度，适合互联网的场景。那为什么Redis依旧要用Hash-based的设计方式呢？是为了更高并发的写入性能吗？
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>MrPolo</a> 


 ```java 
先前在研究 redis cluster 時有注意到,若改為 cluster mode 後有些 command 會無法使用,這部分請問老師會在後面課程講解嗎?
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>流浪地球</a> 


 ```java 
请问老师，集群中的每个切片都是主从配置的吗？
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>篮球不是这么打的</a> 


 ```java 
你好老师，请问下如何算的Redis中每个键值对的大小
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>那时刻</a> 


 ```java 
老师，请问一个Redis延迟的问题。

Redis情况：
单实例Redis，内存10G，最大吞吐量在25000ops/second。数据持久化方式：AOF - 每秒fsync一次。
高峰期的ops是每秒8000，key的数量是4万，内存占用量是2.5G。

遇到的问题：
低峰期Redis延迟0.125ms左右，但是在高峰期的时候，延迟比较大，有1ms左右。

通过INFO命令，看到latest_fork_usec是0。INFO命令其它的信息，我也看了下，感觉都还正常。

我能想到的是通过增加Redis分片机制，来缓解压力。

请问老师，针对这种情况，其一，如何来诊断Redis延迟高的情况呢？其二，如何来缓解Redis延迟高？
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>williamcai</a> 


 ```java 
如果按照键值存储的话，数据量很大，导致该映射占用空间会很大，进而影响查询速度，采用映射卡擦的方式有些与多级目录有异曲同工之妙
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>小喵喵</a> 


 ```java 
请教小老师，我对ASKING命令不太理解，我觉得会返回一个包含bool值的信息，告诉客户端是否可以从这个实例中获取数据，若可以，然后客户端重新发送请求来获取数据，不知道这么理解对不对，请老师解惑。谢谢。
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>zhou</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>Jackey</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>小喵喵</a> 


 ----- 
<a style='font-size:1.5em;font-weight:bold'>写点啥呢</a> 


 ```java 
请问老师，在重定向的机制中，像例子里的情况key1 key2已经迁移到新的实例3，key3 key4还在实例2的时候，如果客户端请求的是key3的话，它是会得到实例2直接返回key3的value还是得到ASK？如果是ASK那么客户端去ASKING 实例3的时候会不会阻塞到key3迁移完成？谢谢
```
 ----- 
<a style='font-size:1.5em;font-weight:bold'>Hugh</a> 


 ----- 
:::